{"cells":[{"cell_type":"markdown","metadata":{"id":"GD9gUQpaBxNa"},"source":["# How to Train YOLOv7 on a Custom Dataset\n","\n","This tutorial is based on the [YOLOv7 repository](https://github.com/WongKinYiu/yolov7) by WongKinYiu. This notebook shows training on **your own custom objects**. Many thanks to WongKinYiu and AlexeyAB for putting this repository together.\n","\n","\n","### **Accompanying Blog Post**\n","\n","We recommend that you follow along in this notebook while reading the blog post on [how to train YOLOv7](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/), concurrently.\n","\n","### **Steps Covered in this Tutorial**\n","\n","To train our detector we take the following steps:\n","\n","* Install YOLOv7 dependencies\n","* Load custom dataset from Roboflow in YOLOv7 format\n","* Run YOLOv7 training\n","* Evaluate YOLOv7 performance\n","* Run YOLOv7 inference on test images\n","* OPTIONAL: Deployment\n","* OPTIONAL: Active Learning\n","\n","\n","### Preparing a Custom Dataset\n","\n","In this tutorial, we will utilize an open source computer vision dataset from one of the 90,000+ available on [Roboflow Universe](https://universe.roboflow.com).\n","\n","If you already have your own images (and, optionally, annotations), you can convert your dataset using [Roboflow](https://roboflow.com), a set of tools developers use to build better computer vision models quickly and accurately. 100k+ developers use roboflow for (automatic) annotation, converting dataset formats (like to YOLOv7), training, deploying, and improving their datasets/models.\n","\n","Follow [the getting started guide here](https://docs.roboflow.com/quick-start) to create and prepare your own custom dataset."]},{"cell_type":"markdown","metadata":{"id":"7mGmQbAO5pQb"},"source":["#Install Dependencies\n","\n","_(Remember to choose GPU in Runtime if not already selected. Runtime --\u003e Change Runtime Type --\u003e Hardware accelerator --\u003e GPU)_"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12064,"status":"ok","timestamp":1672124211289,"user":{"displayName":"Fateme Vaez","userId":"01390577512771264803"},"user_tz":-210},"id":"nD-uPyQ_2jiN","outputId":"6444bb78-0837-4b31-b82e-92ff9ce22223"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'yolov7'...\n","remote: Enumerating objects: 1100, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 1100 (delta 1), reused 0 (delta 0), pack-reused 1094\u001b[K\n","Receiving objects: 100% (1100/1100), 69.91 MiB | 13.92 MiB/s, done.\n","Resolving deltas: 100% (508/508), done.\n","/content/yolov7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib\u003e=3.2.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n","Requirement already satisfied: numpy\u003e=1.18.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n","Requirement already satisfied: opencv-python\u003e=4.1.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n","Requirement already satisfied: Pillow\u003e=7.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n","Requirement already satisfied: PyYAML\u003e=5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (6.0)\n","Requirement already satisfied: requests\u003e=2.23.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n","Requirement already satisfied: scipy\u003e=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (1.7.3)\n","Requirement already satisfied: torch!=1.12.0,\u003e=1.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (1.13.0+cu116)\n","Requirement already satisfied: torchvision!=0.13.0,\u003e=0.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (0.14.0+cu116)\n","Requirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (4.64.1)\n","Requirement already satisfied: protobuf\u003c4.21.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 14)) (3.19.6)\n","Requirement already satisfied: tensorboard\u003e=2.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 17)) (2.9.1)\n","Requirement already satisfied: pandas\u003e=1.1.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 21)) (1.3.5)\n","Requirement already satisfied: seaborn\u003e=0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 22)) (0.11.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 34)) (7.9.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 35)) (5.4.8)\n","Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib\u003e=3.2.2-\u003e-r requirements.txt (line 4)) (3.0.9)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib\u003e=3.2.2-\u003e-r requirements.txt (line 4)) (0.11.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib\u003e=3.2.2-\u003e-r requirements.txt (line 4)) (1.4.4)\n","Requirement already satisfied: python-dateutil\u003e=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib\u003e=3.2.2-\u003e-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests\u003e=2.23.0-\u003e-r requirements.txt (line 9)) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests\u003e=2.23.0-\u003e-r requirements.txt (line 9)) (2022.12.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests\u003e=2.23.0-\u003e-r requirements.txt (line 9)) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.8/dist-packages (from requests\u003e=2.23.0-\u003e-r requirements.txt (line 9)) (2.10)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch!=1.12.0,\u003e=1.7.0-\u003e-r requirements.txt (line 11)) (4.4.0)\n","Requirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (1.51.1)\n","Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (1.8.1)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (1.3.0)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (57.4.0)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (1.0.1)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (2.15.0)\n","Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (0.38.4)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (3.4.1)\n","Requirement already satisfied: pytz\u003e=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas\u003e=1.1.4-\u003e-r requirements.txt (line 21)) (2022.6)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (5.2.0)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (0.2.8)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (4.9)\n","Requirement already satisfied: six\u003e=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (1.15.0)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (1.3.1)\n","Requirement already satisfied: importlib-metadata\u003e=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (5.1.0)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (3.11.0)\n","Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (0.4.8)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003e=2.4.1-\u003e-r requirements.txt (line 17)) (3.2.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython-\u003e-r requirements.txt (line 34)) (0.2.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython-\u003e-r requirements.txt (line 34)) (2.6.1)\n","Requirement already satisfied: prompt-toolkit\u003c2.1.0,\u003e=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython-\u003e-r requirements.txt (line 34)) (2.0.10)\n","Requirement already satisfied: traitlets\u003e=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython-\u003e-r requirements.txt (line 34)) (5.7.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython-\u003e-r requirements.txt (line 34)) (0.7.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython-\u003e-r requirements.txt (line 34)) (4.4.2)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython-\u003e-r requirements.txt (line 34)) (4.8.0)\n","Collecting jedi\u003e=0.10\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 34.7 MB/s \n","\u001b[?25hRequirement already satisfied: parso\u003c0.9.0,\u003e=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi\u003e=0.10-\u003eipython-\u003e-r requirements.txt (line 34)) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit\u003c2.1.0,\u003e=2.0.0-\u003eipython-\u003e-r requirements.txt (line 34)) (0.2.5)\n","Requirement already satisfied: ptyprocess\u003e=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect-\u003eipython-\u003e-r requirements.txt (line 34)) (0.7.0)\n","Installing collected packages: jedi, thop\n","Successfully installed jedi-0.18.2 thop-0.1.1.post2209072238\n"]}],"source":["# Download YOLOv7 repository and install requirements\n","!git clone https://github.com/WongKinYiu/yolov7\n","%cd yolov7\n","!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k9WfmB6CfBVm"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"mtJ24mPlyF-S"},"source":["# Download Correctly Formatted Custom Data\n","\n","Next, we'll download our dataset in the right format. Use the `YOLOv7 PyTorch` export. Note that this model requires YOLO TXT annotations, a custom YAML file, and organized directories. The roboflow export writes this for us and saves it in the correct spot.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":25349,"status":"ok","timestamp":1672124260628,"user":{"displayName":"Fateme Vaez","userId":"01390577512771264803"},"user_tz":-210},"id":"49gdbHVPfJD8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting roboflow\n","  Downloading roboflow-0.2.21-py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.0 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.2.2)\n","Collecting urllib3==1.26.6\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 70.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.64.1)\n","Requirement already satisfied: glob2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.7)\n","Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.10)\n","Collecting pyparsing==2.4.7\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 8.0 MB/s \n","\u001b[?25hCollecting requests-toolbelt\n","  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 3.7 MB/s \n","\u001b[?25hRequirement already satisfied: Pillow\u003e=7.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (7.1.2)\n","Collecting chardet==4.0.0\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[K     |████████████████████████████████| 178 kB 66.3 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.15.0)\n","Requirement already satisfied: opencv-python-headless\u003e=4.5.1.48 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.6.0.66)\n","Collecting certifi==2021.5.30\n","  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 77.3 MB/s \n","\u001b[?25hRequirement already satisfied: kiwisolver\u003e=1.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.4.4)\n","Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","Requirement already satisfied: numpy\u003e=1.18.5 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.21.6)\n","Collecting python-dotenv\n","  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.8.2)\n","Collecting cycler==0.10.0\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Requirement already satisfied: PyYAML\u003e=5.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.23.0)\n","Collecting requests\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer\u003c3,\u003e=2 in /usr/local/lib/python3.8/dist-packages (from requests-\u003eroboflow) (2.1.1)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=d94eba2bcbeb535d890fa11310e6e6b8633a6f82a60e2fce331c2558428fead7\n","  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n","Successfully built wget\n","Installing collected packages: urllib3, certifi, requests, pyparsing, cycler, wget, requests-toolbelt, python-dotenv, chardet, roboflow\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2022.12.7\n","    Uninstalling certifi-2022.12.7:\n","      Successfully uninstalled certifi-2022.12.7\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.0.9\n","    Uninstalling pyparsing-3.0.9:\n","      Successfully uninstalled pyparsing-3.0.9\n","  Attempting uninstall: cycler\n","    Found existing installation: cycler 0.11.0\n","    Uninstalling cycler-0.11.0:\n","      Successfully uninstalled cycler-0.11.0\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 3.0.4\n","    Uninstalling chardet-3.0.4:\n","      Successfully uninstalled chardet-3.0.4\n","Successfully installed certifi-2021.5.30 chardet-4.0.0 cycler-0.10.0 pyparsing-2.4.7 python-dotenv-0.21.0 requests-2.28.1 requests-toolbelt-0.10.1 roboflow-0.2.21 urllib3-1.26.6 wget-3.2\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","cycler","pyparsing"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","Downloading Dataset Version Zip in Detection_Melanoma-1 to yolov7pytorch: 100% [13440792 / 13440792] bytes\n"]},{"name":"stderr","output_type":"stream","text":["Extracting Dataset Version Zip to Detection_Melanoma-1 in yolov7pytorch:: 100%|██████████| 812/812 [00:00\u003c00:00, 2476.26it/s]\n"]}],"source":["# REPLACE with your custom code snippet generated above\n","!pip install roboflow\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"YhUeHgJ65mHntw94eqpT\")\n","project = rf.workspace(\"fateme-vaez\").project(\"detection_melanoma\")\n","dataset = project.version(1).download(\"yolov7\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bHfT9gEiBsBd"},"source":["# Begin Custom Training\n","\n","We're ready to start custom training.\n","\n","NOTE: We will only modify one of the YOLOv7 training defaults in our example: `epochs`. We will adjust from 300 to 100 epochs in our example for speed. If you'd like to change other settings, see details in [our accompanying blog post](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/)."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":633,"status":"ok","timestamp":1672124306826,"user":{"displayName":"Fateme Vaez","userId":"01390577512771264803"},"user_tz":-210},"id":"bUbmy674bhpD","outputId":"aa1c2e3c-2779-42b4-ab08-7f342e26e313"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolov7\n","--2022-12-27 06:58:26--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221227%2Fus-east-1%2Fs3%2Faws4_request\u0026X-Amz-Date=20221227T065755Z\u0026X-Amz-Expires=300\u0026X-Amz-Signature=640ed7b994177e176a6b9522cf5dac2e67e1f2472f74e240e7413b10d02816ce\u0026X-Amz-SignedHeaders=host\u0026actor_id=0\u0026key_id=0\u0026repo_id=511187726\u0026response-content-disposition=attachment%3B%20filename%3Dyolov7.pt\u0026response-content-type=application%2Foctet-stream [following]\n","--2022-12-27 06:58:26--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221227%2Fus-east-1%2Fs3%2Faws4_request\u0026X-Amz-Date=20221227T065755Z\u0026X-Amz-Expires=300\u0026X-Amz-Signature=640ed7b994177e176a6b9522cf5dac2e67e1f2472f74e240e7413b10d02816ce\u0026X-Amz-SignedHeaders=host\u0026actor_id=0\u0026key_id=0\u0026repo_id=511187726\u0026response-content-disposition=attachment%3B%20filename%3Dyolov7.pt\u0026response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 75587165 (72M) [application/octet-stream]\n","Saving to: ‘yolov7.pt’\n","\n","yolov7.pt           100%[===================\u003e]  72.08M   444MB/s    in 0.2s    \n","\n","2022-12-27 06:58:27 (444 MB/s) - ‘yolov7.pt’ saved [75587165/75587165]\n","\n"]}],"source":["# download COCO starting checkpoint\n","%cd /content/yolov7\n","!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13604,"status":"ok","timestamp":1672124398684,"user":{"displayName":"Fateme Vaez","userId":"01390577512771264803"},"user_tz":-210},"id":"1iqOPKjr22mL","outputId":"86551050-60bc-4840-828a-5c05185ad1b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolov7\n","YOLOR 🚀 v0.1-117-g8e9f0b7 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n","\n","Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=False, cfg='/content/yolov7/cfg/training/yolov7.yaml', data='/content/yolov7/Detection_Melanoma-1/data.yaml', device='', entity=None, epochs=10, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, v5_metric=False, weights='yolov7.pt', workers=8, world_size=1)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights \u0026 Biases for YOLOR logging with 'pip install wandb' (recommended)\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 12                -1  1         0  models.common.MP                        []                            \n"," 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n"," 25                -1  1         0  models.common.MP                        []                            \n"," 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 38                -1  1         0  models.common.MP                        []                            \n"," 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n"," 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n"," 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 76                -1  1         0  models.common.MP                        []                            \n"," 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n"," 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 89                -1  1         0  models.common.MP                        []                            \n"," 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n"," 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n"," 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n","102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n","103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n","104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n","105   [102, 103, 104]  1    460282  models.yolo.IDetect                     [80, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n","/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 415 layers, 37622682 parameters, 37622682 gradients, 106.5 GFLOPS\n","\n","Transferred 558/566 items from yolov7.pt\n","Scaled weight_decay = 0.0005\n","Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Detection_Melanoma-1/train/labels' images and labels... 279 found, 0 missing, 279 empty, 0 corrupted: 100% 279/279 [00:00\u003c00:00, 5196.85it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: Detection_Melanoma-1/train/labels.cache\n","Traceback (most recent call last):\n","  File \"train.py\", line 616, in \u003cmodule\u003e\n","    train(hyp, opt, device, tb_writer)\n","  File \"train.py\", line 249, in train\n","    mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class\n","  File \"/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py\", line 40, in _amax\n","    return umr_maximum(a, axis, None, out, keepdims, initial, where)\n","ValueError: zero-size array to reduction operation maximum which has no identity\n"]}],"source":["# run this cell to begin training\n","%cd /content/yolov7\n","!python train.py --batch 16 --cfg /content/yolov7/cfg/training/yolov7.yaml --epochs 10 --data /content/yolov7/Detection_Melanoma-1/data.yaml --weights 'yolov7.pt' \n"]},{"cell_type":"markdown","metadata":{"id":"0W0MpUaTCJro"},"source":["# Evaluation\n","\n","We can evaluate the performance of our custom training using the provided evalution script.\n","\n","Note we can adjust the below custom arguments. For details, see [the arguments accepted by detect.py](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4cfnLtTCIce","outputId":"ef69278d-24ae-4df5-d6c3-4368ebf40eb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.1, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='/content/f.mp4', update=False, view_img=False, weights=['runs/train/exp2/weights/best.pt'])\n","YOLOR 🚀 v0.1-115-g072f76c torch 1.12.1+cu113 CPU\n","\n","Traceback (most recent call last):\n","  File \"detect.py\", line 196, in \u003cmodule\u003e\n","    detect()\n","  File \"detect.py\", line 34, in detect\n","    model = attempt_load(weights, map_location=device)  # load FP32 model\n","  File \"/content/yolov7/models/experimental.py\", line 252, in attempt_load\n","    ckpt = torch.load(w, map_location=map_location)  # load\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 699, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n","    super(_open_file, self).__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: 'runs/train/exp2/weights/best.pt'\n"]}],"source":["# Run evaluation\n","!python detect.py --weights runs/train/exp2/weights/best.pt --conf 0.1 --source /content/f.mp4\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"6AGhNOSSHY4_","outputId":"5110440e-0a77-4121-9a31-5ad34a4ad19b"},"outputs":[{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-2-5e1874757526\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimageName\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/f.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#assuming JPG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m\u003c\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 10\u001b[0;31m       \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimageName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ACCEPTABLE_EMBEDDINGS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1195\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot embed the '%s' image format\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mimetype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_MIMETYPES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Cannot embed the 'mp4' image format"]}],"source":["#display inference on ALL test images\n","\n","import glob\n","from IPython.display import Image, display\n","\n","i = 0\n","limit = 10000 # max images to print\n","for imageName in glob.glob('/content/yolov7/runs/detect/exp3/*.jpg'): #assuming JPG\n","    if i \u003c limit:\n","      display(Image(filename=imageName))\n","      print(\"\\n\")\n","    i = i + 1\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CMOfi7eLJCT3"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"aMumI7a2JDAN"},"source":["# Reparameterize for Inference\n","\n","https://github.com/WongKinYiu/yolov7/blob/main/tools/reparameterization.ipynb"]},{"cell_type":"markdown","metadata":{"id":"4jn4kCtgKiGO"},"source":["# OPTIONAL: Deployment\n","\n","To deploy, you'll need to export your weights and save them to use later."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWOok8abrCsL","outputId":"cbd9bfe1-9601-4b2c-d868-1fc08be7deb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: runs/detect/ (stored 0%)\n","  adding: runs/detect/exp/ (stored 0%)\n","\tzip warning: name not matched: runs/train/exp/weights/best.pt\n","\n","zip error: Nothing to do! (try: zip -r export.zip . -i runs/train/exp/weights/best.pt)\n","\tzip warning: name not matched: runs/train/exp/*\n","\n","zip error: Nothing to do! (export.zip)\n"]}],"source":["1# optional, zip to download weights and results locally\n","\n","!zip -r export.zip runs/detect\n","!zip -r export.zip runs/train/exp/weights/best.pt\n","!zip export.zip runs/train/exp/*"]},{"cell_type":"markdown","metadata":{"id":"f41PvE5gKhYw"},"source":["# OPTIONAL: Active Learning Example\n","\n","Once our first training run is complete, we should use our model to help identify which images are most problematic in order to investigate, annotate, and improve our dataset (and, therefore, model).\n","\n","To do that, we can execute code that automatically uploads images back to our hosted dataset if the image is a specific class or below a given confidence threshold.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mcINqQS7Kt3-"},"outputs":[],"source":["# # setup access to your workspace\n","# rf = Roboflow(api_key=\"YOUR_API_KEY\")                               # used above to load data\n","# inference_project =  rf.workspace().project(\"YOUR_PROJECT_NAME\")    # used above to load data\n","# model = inference_project.version(1).model\n","\n","# upload_project = rf.workspace().project(\"YOUR_PROJECT_NAME\")\n","\n","# print(\"inference reference point: \", inference_project)\n","# print(\"upload destination: \", upload_project)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cEl1NVE3LSD_"},"outputs":[],"source":["# # example upload: if prediction is below a given confidence threshold, upload it \n","\n","# confidence_interval = [10,70]                                   # [lower_bound_percent, upper_bound_percent]\n","\n","# for prediction in predictions:                                  # predictions list to loop through\n","#   if(prediction['confidence'] * 100 \u003e= confidence_interval[0] and \n","#           prediction['confidence'] * 100 \u003c= confidence_interval[1]):\n","        \n","#           # upload on success!\n","#           print(' \u003e\u003e image uploaded!')\n","#           upload_project.upload(image, num_retry_uploads=3)     # upload image in question"]},{"cell_type":"markdown","metadata":{"id":"LVpCFeU-K4gb"},"source":["# Next steps\n","\n","Congratulations, you've trained a custom YOLOv7 model! Next, start thinking about deploying and [building an MLOps pipeline](https://docs.roboflow.com) so your model gets better the more data it sees in the wild."]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}